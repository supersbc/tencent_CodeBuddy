"""
TDSQL éƒ¨ç½²èµ„æºé¢„æµ‹ç³»ç»Ÿ - å®Œæ•´ç‰ˆ
æ•´åˆï¼šéƒ¨ç½²é¢„æµ‹ã€æ¨¡å‹åº“ç®¡ç†ã€è‡ªä¸»è®­ç»ƒ
"""

# ä¿®å¤OpenBLASçº¿ç¨‹èµ„æºé—®é¢˜ - å¿…é¡»åœ¨å¯¼å…¥ä»»ä½•ç§‘å­¦è®¡ç®—åº“ä¹‹å‰è®¾ç½®
import os
os.environ['OPENBLAS_NUM_THREADS'] = '4'
os.environ['OMP_NUM_THREADS'] = '4'
os.environ['MKL_NUM_THREADS'] = '4'

from flask import Flask, render_template, request, jsonify
import json
from werkzeug.utils import secure_filename
from datetime import datetime

app = Flask(__name__)

# é…ç½®
UPLOAD_FOLDER = 'uploads'
ALLOWED_EXTENSIONS = {'png', 'jpg', 'jpeg', 'gif', 'bmp', 'xlsx', 'xls', 'pdf', 'json', 'txt'}
app.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER
app.config['MAX_CONTENT_LENGTH'] = 32 * 1024 * 1024

# åˆ›å»ºå¿…è¦ç›®å½•
os.makedirs(UPLOAD_FOLDER, exist_ok=True)
os.makedirs('model_libraries', exist_ok=True)
os.makedirs('training_data', exist_ok=True)

print("\n" + "=" * 60)
print("ğŸš€ TDSQL éƒ¨ç½²èµ„æºé¢„æµ‹ç³»ç»Ÿ v4.2 (å®Œæ•´ç‰ˆ)")
print("=" * 60)

# å»¶è¿Ÿå¯¼å…¥æ¨¡å—
predictor = None
library_manager = None
training_system = None
model = None

def get_predictor():
    """å»¶è¿ŸåŠ è½½é¢„æµ‹å™¨"""
    global predictor
    if predictor is None:
        print("ğŸ“¦ æ­£åœ¨åŠ è½½é¢„æµ‹å¼•æ“...")
        from deployment_predictor import DeploymentResourcePredictor
        predictor = DeploymentResourcePredictor()
        print("âœ… é¢„æµ‹å¼•æ“åŠ è½½å®Œæˆ")
    return predictor

def get_library_manager():
    """å»¶è¿ŸåŠ è½½æ¨¡å‹åº“ç®¡ç†å™¨"""
    global library_manager
    if library_manager is None:
        print("ğŸ“¦ æ­£åœ¨åŠ è½½æ¨¡å‹åº“ç®¡ç†å™¨...")
        from model_library_manager import ModelLibraryManager
        library_manager = ModelLibraryManager()
        print("âœ… æ¨¡å‹åº“ç®¡ç†å™¨åŠ è½½å®Œæˆ")
    return library_manager

def get_training_system():
    """å»¶è¿ŸåŠ è½½è®­ç»ƒç³»ç»Ÿ"""
    global training_system, model
    if training_system is None:
        print("ğŸ“¦ æ­£åœ¨åŠ è½½è®­ç»ƒç³»ç»Ÿ...")
        from model import TDSQLArchitecturePredictor
        from training_system import TrainingSystem
        model = TDSQLArchitecturePredictor()
        training_system = TrainingSystem(model)
        print("âœ… è®­ç»ƒç³»ç»ŸåŠ è½½å®Œæˆ")
    return training_system

def allowed_file(filename):
    return '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS

# ==================== é¡µé¢è·¯ç”± ====================

@app.route('/')
def index():
    """ä¸»é¡µ - å¯¼èˆªé¡µé¢"""
    return render_template('navigation.html')

@app.route('/nav')
def navigation():
    """å¯¼èˆªé¡µé¢ï¼ˆåˆ«åï¼‰"""
    return render_template('navigation.html')

@app.route('/predict')
def predict_page():
    """éƒ¨ç½²èµ„æºé¢„æµ‹é¡µé¢ï¼ˆæ–°ç‰ˆï¼‰"""
    return render_template('predict_v2.html')

@app.route('/predict_old')
def predict_page_old():
    """éƒ¨ç½²èµ„æºé¢„æµ‹é¡µé¢ï¼ˆæ—§ç‰ˆï¼‰"""
    return render_template('index.html')

@app.route('/model_library')
def model_library():
    """æ¨¡å‹åº“ç®¡ç†é¡µé¢"""
    return render_template('model_library.html')

@app.route('/learning')
def learning():
    """å­¦ä¹ ç³»ç»Ÿé¡µé¢"""
    return render_template('index_learning.html')

@app.route('/test_predict')
def test_predict():
    """æµ‹è¯•é¢„æµ‹æ¥å£é¡µé¢"""
    return render_template('test_simple.html')

@app.route('/test_debug')
def test_debug():
    """è°ƒè¯•æµ‹è¯•é¡µé¢"""
    return render_template('test_simple.html')

# ==================== APIè·¯ç”± ====================

@app.route('/api/health', methods=['GET'])
def health_check():
    """å¥åº·æ£€æŸ¥"""
    return jsonify({
        'status': 'ok',
        'version': '4.0',
        'message': 'TDSQLéƒ¨ç½²èµ„æºé¢„æµ‹ç³»ç»Ÿè¿è¡Œæ­£å¸¸'
    })

@app.route('/api/predict', methods=['POST'])
def predict():
    """éƒ¨ç½²èµ„æºé¢„æµ‹API"""
    try:
        raw = request.get_json() or {}
        
        # è°ƒè¯•ï¼šæ‰“å°æ”¶åˆ°çš„åŸå§‹æ•°æ®
        print("\n" + "=" * 60)
        print("ğŸ“¥ æ”¶åˆ°çš„è¯·æ±‚å‚æ•°:")
        print(f"  enable_xinchuan: {raw.get('enable_xinchuan')}")
        print(f"  xinchuan_mode: {raw.get('xinchuan_mode')}")
        print(f"  å…¨éƒ¨å‚æ•°: {raw}")
        print("=" * 60 + "\n")
        
        # ç»Ÿä¸€å­—æ®µæ˜ å°„ï¼ˆå…¼å®¹æ™®é€šç‰ˆ/ä¸“ä¸šç‰ˆè¡¨å•å­—æ®µï¼‰
        data = {}
        
        # æ•°æ®è§„æ¨¡
        data['data_volume'] = (
            raw.get('current_data_size_gb')
            or raw.get('total_data_size_gb')
            or raw.get('future_data_size_gb')
            or raw.get('data_volume')
            or 100
        )
        
        # æ€§èƒ½å‚æ•°
        data['qps'] = raw.get('qps') or raw.get('normal_qps') or raw.get('peak_qps') or 1000
        data['tps'] = raw.get('tps') or raw.get('normal_tps') or raw.get('peak_tps') or int(data['qps'] * 0.3)
        
        # å¹¶å‘/è¿æ¥
        data['concurrent_users'] = (
            raw.get('concurrent_users')
            or raw.get('concurrent_connections')
            or raw.get('avg_concurrent_connections')
            or 100
        )
        
        # è¡Œä¸š/HA
        data['industry'] = raw.get('industry') or raw.get('industry_type') or 'general'
        need_ha = raw.get('need_high_availability') is True
        data['ha_level'] = 'high' if need_ha else 'standard'
        
        # æ•°æ®å¢é•¿ç‡ï¼ˆè½¬ä¸ºæ¯”ä¾‹ï¼‰
        growth = raw.get('data_growth_rate')
        if isinstance(growth, (int, float)) and growth > 1:
            data['data_growth_rate'] = float(growth) / 100.0
        else:
            data['data_growth_rate'] = growth if isinstance(growth, (int, float)) else 0.3
        
        # å…¶ä»–å¯é€‰éœ€æ±‚
        data['need_disaster_recovery'] = bool(raw.get('need_disaster_recovery'))
        data['need_read_write_split'] = bool(raw.get('need_read_write_split'))
        
        # ä¿¡åˆ›æ¨¡å¼å‚æ•°
        enable_xinchuan = raw.get('enable_xinchuan', False)  # é»˜è®¤å…³é—­ï¼Œéœ€è¦ç”¨æˆ·ä¸»åŠ¨å‹¾é€‰
        xinchuan_mode = raw.get('xinchuan_mode', 'standard')  # é»˜è®¤æ ‡å‡†ä¿¡åˆ›
        
        # æ— è®ºæ˜¯å¦å¯ç”¨ä¿¡åˆ›æ¨¡å¼ï¼Œéƒ½ä½¿ç”¨æ–°ç‰ˆé¢„æµ‹å™¨ï¼ˆç¡®ä¿ç”Ÿæˆå®Œæ•´çš„è®¾å¤‡æ¸…å•ï¼‰
        from deployment_predictor_xinchuan import DeploymentResourcePredictorXinChuan
        
        # è½¬æ¢æ•°æ®æ ¼å¼ï¼ˆç»Ÿä¸€å®šä¹‰ï¼‰
        common_data = {
            'data_size_gb': data['data_volume'] * 1024,  # è½¬æ¢ä¸ºGB
            'transactions_per_day': data['tps'] * 86400,
            'max_connections': data['concurrent_users'],
            'business_type': 'OLTP',
            'high_availability': need_ha,
            'disaster_recovery': data['need_disaster_recovery']
        }
        
        # å¦‚æœå¯ç”¨ä¿¡åˆ›æ¨¡å¼ï¼Œç”Ÿæˆä¼ ç»Ÿæ–¹æ¡ˆå’Œä¿¡åˆ›æ–¹æ¡ˆçš„å®Œæ•´å¯¹æ¯”
        if enable_xinchuan:
            
            # ç”Ÿæˆä¼ ç»Ÿæ–¹æ¡ˆ(ä½¿ç”¨å›½å¤–å“ç‰Œè®¾å¤‡) - ç‹¬ç«‹æ¶æ„è®¾è®¡
            traditional_predictor = DeploymentResourcePredictorXinChuan(xinchuan_mode='off')
            traditional_result = traditional_predictor.predict(common_data)
            
            # ç”Ÿæˆä¿¡åˆ›æ–¹æ¡ˆ(ä½¿ç”¨å›½äº§è®¾å¤‡) - ç‹¬ç«‹æ¶æ„è®¾è®¡
            xc_predictor = DeploymentResourcePredictorXinChuan(xinchuan_mode=xinchuan_mode)
            xc_result = xc_predictor.predict(common_data)
            
            # è®¡ç®—çœŸå®çš„æˆæœ¬å·®å¼‚
            traditional_cost = traditional_result.get('cost_breakdown', {}).get('total_initial_cost', 0)
            xinchuan_cost = xc_result.get('cost_breakdown', {}).get('total_initial_cost', 0)
            cost_savings = traditional_cost - xinchuan_cost
            savings_percent = (cost_savings / traditional_cost * 100) if traditional_cost > 0 else 0
            
            # ä½¿ç”¨ä¼ ç»Ÿæ–¹æ¡ˆä½œä¸ºåŸºç¡€ç»“æœï¼ˆç¡®ä¿å‰ç«¯æ˜¾ç¤ºä¸€è‡´ï¼‰
            result = traditional_result.copy()
            
            # å…ˆè·å–æˆæœ¬æ˜ç»†ï¼ˆé¿å…å˜é‡æœªå®šä¹‰é”™è¯¯ï¼‰
            traditional_cost_breakdown = traditional_result.get('cost_breakdown', {})
            traditional_equipment = traditional_result.get('equipment_list', [])
            traditional_architecture = traditional_result.get('architecture', {})
            
            # é€‚é…å‰ç«¯å­—æ®µåï¼ˆå…¼å®¹æ—§ç‰ˆæ˜¾ç¤ºï¼‰
            result['cost'] = {
                'initial_investment': traditional_cost,  # æ˜ å°„åˆ°æ—§å­—æ®µ
                'three_year_tco': traditional_cost * 1.5,  # ä¼°ç®—3å¹´TCO
                'total_hardware': traditional_cost_breakdown.get('hardware_cost', 0),
                'total_software': traditional_cost_breakdown.get('software_cost', 0),
                'annual_operating': traditional_cost * 0.15  # ä¼°ç®—å¹´è¿è¥æˆæœ¬
            }
            
            # è°ƒè¯•ï¼šæ‰“å°è®¾å¤‡æ¸…å•æ•°æ®ï¼ˆéä¿¡åˆ›æ¨¡å¼ï¼‰
            print(f"\nğŸ” è°ƒè¯•(éä¿¡åˆ›æ¨¡å¼) - traditional_equipment æ€»æ•°: {len(traditional_equipment)}")
            if traditional_equipment:
                print(f"ğŸ” è°ƒè¯•(éä¿¡åˆ›æ¨¡å¼) - ç¬¬ä¸€ä¸ªè®¾å¤‡ç¤ºä¾‹: {traditional_equipment[0]}")
            else:
                print("âš ï¸  è°ƒè¯•(éä¿¡åˆ›æ¨¡å¼) - traditional_equipment ä¸ºç©ºåˆ—è¡¨ï¼")
            
            # é€‚é…è®¾å¤‡æ¸…å•å­—æ®µï¼ˆæŒ‰ç±»åˆ«åˆ†ç»„ï¼‰
            servers = [item for item in traditional_equipment if item.get('category') in ['æ•°æ®åº“æœåŠ¡å™¨', 'ä»£ç†æœåŠ¡å™¨', 'ç›‘æ§æœåŠ¡å™¨']]
            network_devices = [item for item in traditional_equipment if item.get('category') in ['æ ¸å¿ƒäº¤æ¢æœº', 'æ¥å…¥äº¤æ¢æœº', 'å®‰å…¨é˜²ç«å¢™']]
            storage_devices = [item for item in traditional_equipment if item.get('category') == 'å­˜å‚¨è®¾å¤‡']
            infrastructure_items = traditional_cost_breakdown.get('infrastructure_items', [])
            
            print(f"ğŸ” è°ƒè¯•(éä¿¡åˆ›æ¨¡å¼) - åˆ†ç±»å: servers={len(servers)}, network={len(network_devices)}, storage={len(storage_devices)}, infrastructure={len(infrastructure_items)}")
            
            result['equipment'] = {
                'servers': servers,
                'network_devices': network_devices,
                'storage': storage_devices,  # âœ… æ”¹ä¸º storageï¼ˆå‰ç«¯æœŸå¾…ï¼‰
                'infrastructure': infrastructure_items  # âœ… æ·»åŠ åŸºç¡€è®¾æ–½æ¸…å•
            }
            result['equipment_list'] = traditional_equipment  # æ–°ç‰ˆå­—æ®µ

            
            # é€‚é…æ¶æ„å­—æ®µ
            result['architecture'] = {
                'type': 'cluster',
                'topology': {
                    'db_nodes': traditional_architecture.get('database_nodes', 0),
                    'proxy_nodes': traditional_architecture.get('proxy_nodes', 0),
                    'monitor_nodes': traditional_architecture.get('monitoring_nodes', 0),
                    'shard_count': 0,
                    'replica_count': 3
                }
            }
            result['cost_breakdown'] = {
                'summary': result['cost'],
                'breakdown': {  # âœ… æ·»åŠ  breakdown åŒ…è£¹å±‚
                    'hardware': {
                        'servers': sum(item.get('total_price', 0) for item in servers),
                        'network_devices': sum(item.get('total_price', 0) for item in network_devices),
                        'storage': sum(item.get('total_price', 0) for item in storage_devices),
                        'infrastructure': traditional_cost_breakdown.get('infrastructure_cost', 0)
                    },
                    'software': {
                        'tdsql_license': 0,  # ä¿¡åˆ›æ¨¡å¼å…è´¹
                        'os_license': sum(item.get('total', 0) for item in traditional_cost_breakdown.get('software_items', []) if 'OS' in item.get('name', '') or 'Red Hat' in item.get('name', '')),
                        'monitoring': 0,
                        'backup': 0
                    },
                    'services': {
                        'deployment': sum(item.get('total_price', 0) for item in infrastructure_items if 'å®æ–½' in item.get('category', '')),
                        'training': sum(item.get('total_price', 0) for item in infrastructure_items if 'åŸ¹è®­' in item.get('category', ''))
                    }
                },
                # åŒæ—¶ä¿ç•™é¡¶å±‚å­—æ®µï¼ˆå‘åå…¼å®¹ï¼‰
                'hardware': {
                    'servers': sum(item.get('total_price', 0) for item in servers),
                    'network_devices': sum(item.get('total_price', 0) for item in network_devices),
                    'storage': sum(item.get('total_price', 0) for item in storage_devices),
                    'infrastructure': traditional_cost_breakdown.get('infrastructure_cost', 0)
                },
                'software': {
                    'tdsql_license': 0,
                    'os_license': sum(item.get('total', 0) for item in traditional_cost_breakdown.get('software_items', []) if 'OS' in item.get('name', '') or 'Red Hat' in item.get('name', '')),
                    'monitoring': 0,
                    'backup': 0
                },
                'services': {
                    'deployment': sum(item.get('total_price', 0) for item in infrastructure_items if 'å®æ–½' in item.get('category', '')),
                    'training': sum(item.get('total_price', 0) for item in infrastructure_items if 'åŸ¹è®­' in item.get('category', ''))
                },
                'software_items': traditional_cost_breakdown.get('software_items', []),
                'annual_operating': {}
            }
            
            # æ·»åŠ å®Œæ•´çš„å¯¹æ¯”ä¿¡æ¯
            result['xinchuan_enabled'] = True
            result['xinchuan_mode'] = xinchuan_mode
            result['traditional_solution'] = traditional_result  # ä¼ ç»Ÿæ–¹æ¡ˆ(ç‹¬ç«‹æ¶æ„)
            result['xinchuan_solution'] = xc_result  # ä¿¡åˆ›æ–¹æ¡ˆ(ç‹¬ç«‹æ¶æ„)
            result['xinchuan_info'] = xc_result.get('xinchuan_info', {})
            result['cost_comparison'] = {
                'traditional_cost': traditional_cost,
                'xinchuan_cost': xinchuan_cost,
                'cost_savings': cost_savings,
                'savings_percent': round(savings_percent, 1),
                'note': f'ä½¿ç”¨ä¿¡åˆ›æ–¹æ¡ˆç›¸æ¯”ä¼ ç»Ÿæ–¹æ¡ˆèŠ‚çº¦ Â¥{cost_savings:,.0f} ({savings_percent:.1f}%)'
            }
        else:
            # ä¸å¯ç”¨ä¿¡åˆ›æ¨¡å¼ï¼Œåªç”Ÿæˆä¼ ç»Ÿæ–¹æ¡ˆï¼ˆå›½å¤–å“ç‰Œï¼‰
            traditional_predictor = DeploymentResourcePredictorXinChuan(xinchuan_mode='off')
            traditional_result = traditional_predictor.predict(common_data)
            
            # è·å–æˆæœ¬å’Œè®¾å¤‡ä¿¡æ¯
            traditional_cost_breakdown = traditional_result.get('cost_breakdown', {})
            traditional_equipment = traditional_result.get('equipment_list', [])
            traditional_architecture = traditional_result.get('architecture', {})
            traditional_cost = traditional_cost_breakdown.get('total_initial_cost', 0)
            
            # ä½¿ç”¨ä¼ ç»Ÿæ–¹æ¡ˆä½œä¸ºç»“æœ
            result = traditional_result.copy()
            
            # é€‚é…å‰ç«¯å­—æ®µåï¼ˆå…¼å®¹æ—§ç‰ˆæ˜¾ç¤ºï¼‰
            result['cost'] = {
                'initial_investment': traditional_cost,
                'three_year_tco': traditional_cost * 1.5,
                'total_hardware': traditional_cost_breakdown.get('hardware_cost', 0),
                'total_software': traditional_cost_breakdown.get('software_cost', 0),
                'annual_operating': traditional_cost * 0.15
            }
            
            # è°ƒè¯•ï¼šæ‰“å°è®¾å¤‡æ¸…å•æ•°æ®ï¼ˆéä¿¡åˆ›æ¨¡å¼ï¼‰
            print(f"\nğŸ” è°ƒè¯•(éä¿¡åˆ›æ¨¡å¼) - traditional_equipment æ€»æ•°: {len(traditional_equipment)}")
            if traditional_equipment:
                print(f"ğŸ” è°ƒè¯•(éä¿¡åˆ›æ¨¡å¼) - ç¬¬ä¸€ä¸ªè®¾å¤‡ç¤ºä¾‹: {traditional_equipment[0]}")
            else:
                print("âš ï¸  è°ƒè¯•(éä¿¡åˆ›æ¨¡å¼) - traditional_equipment ä¸ºç©ºåˆ—è¡¨ï¼")
            
            # é€‚é…è®¾å¤‡æ¸…å•å­—æ®µï¼ˆæŒ‰ç±»åˆ«åˆ†ç»„ï¼‰
            servers = [item for item in traditional_equipment if item.get('category') in ['æ•°æ®åº“æœåŠ¡å™¨', 'ä»£ç†æœåŠ¡å™¨', 'ç›‘æ§æœåŠ¡å™¨']]
            network_devices = [item for item in traditional_equipment if item.get('category') in ['æ ¸å¿ƒäº¤æ¢æœº', 'æ¥å…¥äº¤æ¢æœº', 'å®‰å…¨é˜²ç«å¢™']]
            storage_devices = [item for item in traditional_equipment if item.get('category') == 'å­˜å‚¨è®¾å¤‡']
            infrastructure_items = traditional_cost_breakdown.get('infrastructure_items', [])
            
            print(f"ğŸ” è°ƒè¯•(éä¿¡åˆ›æ¨¡å¼) - åˆ†ç±»å: servers={len(servers)}, network={len(network_devices)}, storage={len(storage_devices)}, infrastructure={len(infrastructure_items)}")
            
            result['equipment'] = {
                'servers': servers,
                'network_devices': network_devices,
                'storage': storage_devices,  # âœ… æ”¹ä¸º storageï¼ˆå‰ç«¯æœŸå¾…ï¼‰
                'infrastructure': infrastructure_items  # âœ… æ·»åŠ åŸºç¡€è®¾æ–½æ¸…å•
            }
            result['equipment_list'] = traditional_equipment

            
            # é€‚é…æ¶æ„å­—æ®µ
            result['architecture'] = {
                'type': 'cluster',
                'topology': {
                    'db_nodes': traditional_architecture.get('database_nodes', 0),
                    'proxy_nodes': traditional_architecture.get('proxy_nodes', 0),
                    'monitor_nodes': traditional_architecture.get('monitoring_nodes', 0),
                    'shard_count': 0,
                    'replica_count': 3
                }
            }
            
            result['cost_breakdown'] = {
                'summary': result['cost'],
                'breakdown': {  # âœ… æ·»åŠ  breakdown åŒ…è£¹å±‚
                    'hardware': {
                        'servers': sum(item.get('total_price', 0) for item in servers),
                        'network_devices': sum(item.get('total_price', 0) for item in network_devices),
                        'storage': sum(item.get('total_price', 0) for item in storage_devices),
                        'infrastructure': traditional_cost_breakdown.get('infrastructure_cost', 0)
                    },
                    'software': {
                        'tdsql_license': 0,
                        'os_license': sum(item.get('total', 0) for item in traditional_cost_breakdown.get('software_items', []) if 'OS' in item.get('name', '') or 'Red Hat' in item.get('name', '')),
                        'monitoring': 0,
                        'backup': 0
                    },
                    'services': {
                        'deployment': sum(item.get('total_price', 0) for item in infrastructure_items if 'å®æ–½' in item.get('category', '')),
                        'training': sum(item.get('total_price', 0) for item in infrastructure_items if 'åŸ¹è®­' in item.get('category', ''))
                    }
                },
                # åŒæ—¶ä¿ç•™é¡¶å±‚å­—æ®µï¼ˆå‘åå…¼å®¹ï¼‰
                'hardware': {
                    'servers': sum(item.get('total_price', 0) for item in servers),
                    'network_devices': sum(item.get('total_price', 0) for item in network_devices),
                    'storage': sum(item.get('total_price', 0) for item in storage_devices),
                    'infrastructure': traditional_cost_breakdown.get('infrastructure_cost', 0)
                },
                'software': {
                    'tdsql_license': 0,
                    'os_license': sum(item.get('total', 0) for item in traditional_cost_breakdown.get('software_items', []) if 'OS' in item.get('name', '') or 'Red Hat' in item.get('name', '')),
                    'monitoring': 0,
                    'backup': 0
                },
                'services': {
                    'deployment': sum(item.get('total_price', 0) for item in infrastructure_items if 'å®æ–½' in item.get('category', '')),
                    'training': sum(item.get('total_price', 0) for item in infrastructure_items if 'åŸ¹è®­' in item.get('category', ''))
                },
                'software_items': traditional_cost_breakdown.get('software_items', []),
                'annual_operating': {}
            }
            
            # æ ‡è®°æœªå¯ç”¨ä¿¡åˆ›æ¨¡å¼
            result['xinchuan_enabled'] = False
        
        return jsonify({
            'success': True,
            'data': result
        })
        
    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/upload', methods=['POST'])
def upload_file():
    """æ–‡ä»¶ä¸Šä¼ API"""
    try:
        if 'file' not in request.files:
            return jsonify({'success': False, 'error': 'æ²¡æœ‰æ–‡ä»¶'}), 400
        
        file = request.files['file']
        if file.filename == '':
            return jsonify({'success': False, 'error': 'æ–‡ä»¶åä¸ºç©º'}), 400
        
        if file and allowed_file(file.filename):
            filename = secure_filename(file.filename)
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            filename = f"{timestamp}_{filename}"
            filepath = os.path.join(app.config['UPLOAD_FOLDER'], filename)
            file.save(filepath)
            
            # è·å–é¢„æµ‹å™¨å¹¶è§£ææ–‡ä»¶
            pred = get_predictor()
            params = pred.parse_file(filepath)
            
            return jsonify({
                'success': True,
                'filename': filename,
                'filepath': filepath,
                'params': params
            })
        else:
            return jsonify({'success': False, 'error': 'ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹'}), 400
            
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500

@app.route('/api/clear_uploads', methods=['POST'])
def clear_uploads():
    """æ¸…é™¤ä¸Šä¼ çš„æ–‡ä»¶"""
    try:
        import shutil
        
        # æ¸…ç©ºuploadsç›®å½•
        if os.path.exists(UPLOAD_FOLDER):
            for filename in os.listdir(UPLOAD_FOLDER):
                file_path = os.path.join(UPLOAD_FOLDER, filename)
                try:
                    if os.path.isfile(file_path):
                        os.unlink(file_path)
                except Exception as e:
                    print(f"åˆ é™¤æ–‡ä»¶å¤±è´¥: {file_path}, é”™è¯¯: {e}")
        
        return jsonify({
            'success': True,
            'message': 'å·²æ¸…é™¤æ‰€æœ‰ä¸Šä¼ æ–‡ä»¶'
        })
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500

# ==================== æ¨¡å‹åº“ç®¡ç† API ====================

@app.route('/api/model_libraries', methods=['GET'])
def get_model_libraries():
    """è·å–å¯ç”¨çš„æ¨¡å‹åº“åˆ—è¡¨"""
    try:
        manager = get_library_manager()
        libraries = manager.list_available_libraries()
        return jsonify({
            'success': True,
            'libraries': libraries
        })
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500

@app.route('/api/model_libraries/<library_id>', methods=['GET'])
def get_model_library(library_id):
    """è·å–æŒ‡å®šæ¨¡å‹åº“è¯¦æƒ…"""
    try:
        manager = get_library_manager()
        library = manager.get_library_info(library_id)
        return jsonify({
            'success': True,
            'library': library
        })
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500

@app.route('/api/model_libraries/<library_id>/download', methods=['POST'])
def download_model_library(library_id):
    """ä¸‹è½½æ¨¡å‹åº“"""
    try:
        manager = get_library_manager()
        result = manager.download_library(library_id)
        return jsonify({
            'success': True,
            'message': f'æ¨¡å‹åº“ {library_id} ä¸‹è½½æˆåŠŸ',
            'result': result
        })
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500

@app.route('/api/model_libraries/installed', methods=['GET'])
def get_installed_libraries():
    """è·å–å·²å®‰è£…çš„æ¨¡å‹åº“"""
    try:
        manager = get_library_manager()
        installed = manager.list_installed_libraries()
        return jsonify({
            'success': True,
            'libraries': installed
        })
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500

@app.route('/api/model_libraries/<library_id>/activate', methods=['POST'])
def activate_library(library_id):
    """æ¿€æ´»æ¨¡å‹åº“"""
    try:
        manager = get_library_manager()
        manager.activate_library(library_id)
        return jsonify({
            'success': True,
            'message': f'æ¨¡å‹åº“ {library_id} å·²æ¿€æ´»'
        })
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500

@app.route('/api/custom_library', methods=['POST'])
def create_custom_library():
    """åˆ›å»ºè‡ªå®šä¹‰æ¨¡å‹åº“"""
    try:
        data = request.get_json()
        manager = get_library_manager()
        result = manager.create_custom_library(
            name=data.get('name'),
            description=data.get('description'),
            industry=data.get('industry'),
            cases=data.get('cases', [])
        )
        return jsonify({
            'success': True,
            'library': result
        })
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500

# ==================== è®­ç»ƒç³»ç»Ÿ API ====================

@app.route('/api/training/cases', methods=['GET'])
def get_training_cases():
    """è·å–è®­ç»ƒæ¡ˆä¾‹åˆ—è¡¨"""
    try:
        trainer = get_training_system()
        cases = trainer.list_cases()
        return jsonify({
            'success': True,
            'cases': cases
        })
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500

@app.route('/api/training/cases', methods=['POST'])
def add_training_case():
    """æ·»åŠ è®­ç»ƒæ¡ˆä¾‹"""
    try:
        data = request.get_json()
        trainer = get_training_system()
        
        case_id = trainer.add_case(
            input_data=data.get('input'),
            output_data=data.get('output'),
            feedback=data.get('feedback')
        )
        
        return jsonify({
            'success': True,
            'case_id': case_id,
            'message': 'è®­ç»ƒæ¡ˆä¾‹å·²æ·»åŠ '
        })
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500

@app.route('/api/training/train', methods=['POST'])
def train_model():
    """è®­ç»ƒæ¨¡å‹"""
    try:
        data = request.get_json()
        trainer = get_training_system()
        
        result = trainer.train(
            epochs=data.get('epochs', 10),
            batch_size=data.get('batch_size', 32)
        )
        
        return jsonify({
            'success': True,
            'result': result
        })
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500

@app.route('/api/training/history', methods=['GET'])
def get_training_history():
    """è·å–è®­ç»ƒå†å²"""
    try:
        trainer = get_training_system()
        history = trainer.get_history()
        return jsonify({
            'success': True,
            'history': history
        })
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500

@app.route('/api/training/evaluate', methods=['POST'])
def evaluate_model():
    """è¯„ä¼°æ¨¡å‹"""
    try:
        data = request.get_json()
        trainer = get_training_system()
        
        result = trainer.evaluate(data.get('test_data'))
        
        return jsonify({
            'success': True,
            'result': result
        })
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500

@app.route('/download_template/<version>')
def download_template(version):
    """ä¸‹è½½Excelæ¨¡æ¿"""
    try:
        from flask import send_file
        if version == 'basic':
            filename = 'éƒ¨ç½²èµ„æºé¢„æµ‹æ¨¡æ¿-æ™®é€šç‰ˆ.xlsx'
        else:
            filename = 'éƒ¨ç½²èµ„æºé¢„æµ‹æ¨¡æ¿-ä¸“ä¸šç‰ˆ.xlsx'
        
        filepath = os.path.join('templates', filename)
        return send_file(filepath, as_attachment=True, download_name=filename)
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500

@app.route('/api/parse_excel', methods=['POST'])
def parse_excel():
    """è§£æä¸Šä¼ çš„Excelæ–‡ä»¶"""
    try:
        if 'file' not in request.files:
            return jsonify({'success': False, 'error': 'æ²¡æœ‰æ–‡ä»¶ä¸Šä¼ '}), 400
        
        file = request.files['file']
        if file.filename == '':
            return jsonify({'success': False, 'error': 'æ–‡ä»¶åä¸ºç©º'}), 400
        
        if not file.filename.endswith(('.xlsx', '.xls')):
            return jsonify({'success': False, 'error': 'åªæ”¯æŒExcelæ–‡ä»¶'}), 400
        
        # ä¿å­˜æ–‡ä»¶
        filename = secure_filename(file.filename)
        filepath = os.path.join(app.config['UPLOAD_FOLDER'], filename)
        file.save(filepath)
        
        # è§£æExcel
        from openpyxl import load_workbook
        wb = load_workbook(filepath)
        ws = wb.active
        
        data = {}
        
        # è¯»å–æ•°æ®ï¼ˆä»ç¬¬5è¡Œå¼€å§‹ï¼Œè·³è¿‡æ ‡é¢˜å’Œè¡¨å¤´ï¼‰
        for row in range(5, ws.max_row + 1):
            param_name = ws.cell(row, 1).value
            param_value = ws.cell(row, 2).value
            
            if param_name and param_value:
                # è½¬æ¢å‚æ•°åä¸ºå­—æ®µå
                field_mapping = {
                    'æ•°æ®è§„æ¨¡ (GB)': 'total_data_size_gb',
                    'å½“å‰æ•°æ®è§„æ¨¡ (GB)': 'current_data_size_gb',
                    'è¡¨æ•°é‡': 'table_count',
                    'QPS (æ¯ç§’æŸ¥è¯¢æ•°)': 'qps',
                    'æ—¥å¸¸QPS': 'normal_qps',
                    'TPS (æ¯ç§’äº‹åŠ¡æ•°)': 'tps',
                    'æ—¥å¸¸TPS': 'normal_tps',
                    'å¹¶å‘è¿æ¥æ•°': 'concurrent_connections',
                    'å¹³å‡å¹¶å‘è¿æ¥æ•°': 'avg_concurrent_connections',
                    'éœ€è¦é«˜å¯ç”¨': 'need_high_availability',
                    'éœ€è¦ç¾å¤‡': 'need_disaster_recovery',
                    'éœ€è¦å¼‚åœ°ç¾å¤‡': 'need_disaster_recovery',
                    'éœ€è¦è¯»å†™åˆ†ç¦»': 'need_read_write_split',
                    'æ•°æ®å¢é•¿ç‡ (%/å¹´)': 'data_growth_rate',
                }
                
                field_name = field_mapping.get(param_name)
                if field_name:
                    # å¤„ç†å¸ƒå°”å€¼
                    if isinstance(param_value, str) and param_value.upper() in ['TRUE', 'FALSE']:
                        data[field_name] = param_value.upper() == 'TRUE'
                    else:
                        data[field_name] = param_value
        
        # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
        os.remove(filepath)
        
        return jsonify({
            'success': True,
            'data': data
        })
        
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500

if __name__ == '__main__':
    print("\n" + "=" * 60)
    print("ğŸš€ TDSQL éƒ¨ç½²èµ„æºé¢„æµ‹ç³»ç»Ÿ v4.3")
    print("=" * 60)
    print(f"ğŸ“ ä¸»é¡µé¢: http://127.0.0.1:18080")
    print(f"ğŸ“ å¯¼èˆªé¡µé¢: http://127.0.0.1:18080/nav")
    print(f"ğŸ“ éƒ¨ç½²é¢„æµ‹: http://127.0.0.1:18080/predict (æ–°ç‰ˆ)")
    print(f"ğŸ“ æ¨¡å‹åº“ç®¡ç†: http://127.0.0.1:18080/model_library")
    print(f"ğŸ“ å­¦ä¹ ç³»ç»Ÿ: http://127.0.0.1:18080/learning")
    print("=" * 60)
    print("âœ¨ åŠŸèƒ½æ¨¡å—:")
    print("  âœ… éƒ¨ç½²èµ„æºé¢„æµ‹ - æ™®é€šç‰ˆ/ä¸“ä¸šç‰ˆåŒæ¨¡å¼")
    print("  âœ… Excelæ¨¡æ¿ - ä¸‹è½½æ¨¡æ¿ï¼Œä¸Šä¼ è‡ªåŠ¨å¡«å……")
    print("  âœ… æ¨¡å‹åº“ç®¡ç† - 8ä¸ªé¢„ç½®æ¨¡å‹åº“")
    print("  âœ… è‡ªä¸»è®­ç»ƒ - ä»å®é™…æ¡ˆä¾‹ä¸­å­¦ä¹ ä¼˜åŒ–")
    print("  âœ… æ–‡ä»¶ä¸Šä¼  - æ”¯æŒJSON/Excel/å›¾ç‰‡/PDF")
    print("=" * 60)
    print()
    
    app.run(
        host='0.0.0.0',
        port=18080,
        debug=False,
        threaded=True,
        use_reloader=False
    )
